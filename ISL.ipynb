{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJb6JN2rnXz2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAKaujrXn-WS",
        "outputId": "e26a0eef-b68c-474d-d63d-c8d539889618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMidpk8WoIa0",
        "outputId": "66e1221d-9328-4157-8fae-8a11ca35f7b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset extracted to: /content/dataset\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the uploaded zip file in Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/ISL_CSLRT_Corpus.zip'\n",
        "extract_path = '/content/dataset'  # Destination folder\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Dataset extracted to: {extract_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqf5yxvmL0jR",
        "outputId": "1c9c05cd-f4a4-4fbc-b09d-26231720cc22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/dataset/ISL_CSLRT_Corpus/Frames_Sentence_Level\"\n",
        "\n",
        "def display_video_from_frames(input_text):\n",
        "    \"\"\"Search for folder, locate first subfolder, compile jpg frames into a video, and display in Colab.\"\"\"\n",
        "    input_text = input_text.lower().strip()\n",
        "\n",
        "    # Step 1: Search for folder named after input text\n",
        "    sentence_folders = os.listdir(dataset_path)\n",
        "    matching_folder = [f for f in sentence_folders if input_text in f.lower()]\n",
        "\n",
        "    if matching_folder:\n",
        "        main_folder_path = os.path.join(dataset_path, matching_folder[0])\n",
        "\n",
        "        # Step 2: Locate first subfolder inside matched folder\n",
        "        subfolders = os.listdir(main_folder_path)\n",
        "        if subfolders:\n",
        "            nested_folder_path = os.path.join(main_folder_path, subfolders[0])  # First subfolder\n",
        "\n",
        "            # Step 3: Retrieve jpg files from the first subfolder\n",
        "            jpg_files = sorted([f for f in os.listdir(nested_folder_path) if f.endswith(\".jpg\")])  # Sort filenames\n",
        "\n",
        "            if jpg_files:\n",
        "                print(f\"Creating video from {len(jpg_files)} frames in '{matching_folder[0]}'...\")\n",
        "\n",
        "                # Step 4: Define video properties\n",
        "                temp_video_path = \"/content/temp_video.mp4\"\n",
        "                frame_example = cv2.imread(os.path.join(nested_folder_path, jpg_files[0]))\n",
        "                height, width, _ = frame_example.shape\n",
        "\n",
        "                fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for mp4 format\n",
        "                video_writer = cv2.VideoWriter(temp_video_path, fourcc, 10, (width, height))  # FPS = 10\n",
        "\n",
        "                # Step 5: Write frames into video\n",
        "                for img_file in jpg_files:\n",
        "                    img_path = os.path.join(nested_folder_path, img_file)\n",
        "                    frame = cv2.imread(img_path)\n",
        "\n",
        "                    if frame is not None:\n",
        "                        frame = cv2.resize(frame, (width, height))  # Resize if needed\n",
        "                        cv2.rectangle(frame, (50, 50), (width-50, height-50), (0, 255, 0), 3)  # Draw rectangle\n",
        "                        video_writer.write(frame)\n",
        "\n",
        "                video_writer.release()  # Save video\n",
        "\n",
        "                # Step 6: Load and display the video frame by frame in Colab\n",
        "                cap = cv2.VideoCapture(temp_video_path)\n",
        "                while cap.isOpened():\n",
        "                    ret, frame = cap.read()\n",
        "                    if not ret:\n",
        "                        break\n",
        "                    cv2_imshow(frame)\n",
        "                    time.sleep(0.05)\n",
        "\n",
        "                cap.release()\n",
        "            else:\n",
        "                print(f\"No jpg files found inside subfolder '{subfolders[0]}'.\")\n",
        "        else:\n",
        "            print(f\"No subfolders found inside folder '{matching_folder[0]}'.\")\n",
        "    else:\n",
        "        print(f\"No matching folder found for: '{input_text}'\")\n",
        "        return input_text  # Return input text if no match is found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY_nWPRUL_NI",
        "outputId": "f157a1f5-59c3-4ee1-dd9e-3e2efc35ee41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subfolders inside: /content/dataset/ISL_CSLRT_Corpus/Frames_Sentence_Level\n",
            "1. what do you do\n",
            "2. you need a medicine, take this one\n",
            "3. This place is beautiful\n",
            "4. you are bad\n",
            "5. i got hurt\n",
            "6. i am so sorry to hear that\n",
            "7. pour some more water into the glass\n",
            "8. do not take it to the heart\n",
            "9. i am tired\n",
            "10. how can i trust you\n",
            "11. how are things\n",
            "12. help me\n",
            "13. do not abuse him\n",
            "14. you can do it\n",
            "15. i do not agree\n",
            "16. what did you tell him\n",
            "17. i am sitting in the class\n",
            "18. i promise\n",
            "19. i somehow got to know about it\n",
            "20. he she is my friend\n",
            "21. what are you doing\n",
            "22. He is going into the room\n",
            "23. i am feeling bored\n",
            "24. how dare you\n",
            "25. hi how are you\n",
            "26. i am not really sure\n",
            "27. tell me truth\n",
            "28. i am really grateful\n",
            "29. i am crying\n",
            "30. congratulations\n",
            "31. wear the shirt\n",
            "32. what you want\n",
            "33. try to understand\n",
            "34. i enjoyed a lot\n",
            "35. why are you disappointed\n",
            "36. he came by train\n",
            "37. that is so kind of you\n",
            "38. who are you\n",
            "39. let him take time\n",
            "40. when will the train leave\n",
            "41. i do not like it\n",
            "42. serve the food\n",
            "43. what happened\n",
            "44. i am very happy\n",
            "45. could you please talk slower\n",
            "46. what have you planned for your career\n",
            "47. i am fine. thank you sir\n",
            "48. what do you want to become\n",
            "49. he is on the way\n",
            "50. i can not help you there\n",
            "51. do me a favour\n",
            "52. i like you i love you\n",
            "53. i was stopped by some one\n",
            "54. speak softly\n",
            "55. how can i help you\n",
            "56. where are you from\n",
            "57. you are good\n",
            "58. i do not mean it\n",
            "59. take care of yourself\n",
            "60. go and sleep\n",
            "61. prepare the bed\n",
            "62. shall we go outside\n",
            "63. why are you angry\n",
            "64. can you repeat that please\n",
            "65. thank you so much\n",
            "66. we are all with you\n",
            "67. had your food\n",
            "68. i really appreciate it\n",
            "69. i am in dilemma what to do\n",
            "70. i am feeling cold\n",
            "71. what is your phone number\n",
            "72. which collegeschool are you from\n",
            "73. can i help you\n",
            "74. do you need something\n",
            "75. i need water\n",
            "76. nice to meet you\n",
            "77. what do you think\n",
            "78. comb your hair\n",
            "79. you do anything, i do not care\n",
            "80. are you free today\n",
            "81. i am (age)\n",
            "82. are you hiding something\n",
            "83. i am afraid of that\n",
            "84. bring water for me\n",
            "85. it does not make any difference to me\n",
            "86. do not worry\n",
            "87. turn on light turn off light\n",
            "88. how old are you\n",
            "89. you are welcome\n",
            "90. why are you crying\n",
            "91. do not hurt me\n",
            "92. my name is xxxxxxxx\n",
            "93. do not be stubborn\n",
            "94. it was nice chatting with you\n",
            "95. i am suffering from fever\n",
            "96. do not make me angry\n",
            "97. i am hungry\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Define the main folder path\n",
        "main_folder = \"/content/dataset/ISL_CSLRT_Corpus/Frames_Sentence_Level\"  # Update with your actual path\n",
        "\n",
        "def list_subfolders(main_folder):\n",
        "    \"\"\"Lists all subfolders inside the given main folder.\"\"\"\n",
        "    if os.path.exists(main_folder):\n",
        "        subfolders = [f for f in os.listdir(main_folder) if os.path.isdir(os.path.join(main_folder, f))]\n",
        "        print(\"Subfolders inside:\", main_folder)\n",
        "        for idx, folder in enumerate(subfolders, start=1):\n",
        "            print(f\"{idx}. {folder}\")\n",
        "        return subfolders\n",
        "    else:\n",
        "        print(\"Error: Main folder not found!\")\n",
        "        return []\n",
        "\n",
        "# Run the function\n",
        "subfolder_list = list_subfolders(main_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaloA5HSOc4p"
      },
      "outputs": [],
      "source": [
        "def display_frames_in_box(input_text):\n",
        "    \"\"\"Search for a matching folder, display each jpg frame one at a time inside a fixed square box.\"\"\"\n",
        "    input_text = input_text.lower().strip()\n",
        "\n",
        "    # Step 1: Locate the folder named after the input text\n",
        "    sentence_folders = os.listdir(dataset_path)\n",
        "    matching_folder = [f for f in sentence_folders if input_text in f.lower()]\n",
        "\n",
        "    if matching_folder:\n",
        "        main_folder_path = os.path.join(dataset_path, matching_folder[0])\n",
        "\n",
        "        # Step 2: Locate the first subfolder inside the matched folder\n",
        "        subfolders = os.listdir(main_folder_path)\n",
        "        if subfolders:\n",
        "            nested_folder_path = os.path.join(main_folder_path, subfolders[0])\n",
        "\n",
        "            # Step 3: Retrieve jpg files inside the subfolder\n",
        "            jpg_files = sorted([f for f in os.listdir(nested_folder_path) if f.endswith(\".jpg\")])\n",
        "\n",
        "            if jpg_files:\n",
        "                print(f\"Displaying frames in a fixed square box ({len(jpg_files)} images) faster...\")\n",
        "\n",
        "                # Step 4: Show each jpg frame one at a time inside a fixed box\n",
        "                for img_file in jpg_files:\n",
        "                    img_path = os.path.join(nested_folder_path, img_file)\n",
        "                    frame = cv2.imread(img_path)\n",
        "\n",
        "                    if frame is not None:\n",
        "                        frame = cv2.resize(frame, (400, 400))  # Fixed square size\n",
        "\n",
        "                        # Draw a fixed box around the frame\n",
        "                        cv2.rectangle(frame, (20, 20), (380, 380), (0, 255, 0), 4)\n",
        "\n",
        "                        clear_output(wait=True)  # Clear previous frame for clean display\n",
        "                        cv2_imshow(frame)  # Display frame in Colab\n",
        "                        time.sleep(0.3)  # Reduced delay for faster playback\n",
        "            else:\n",
        "                print(f\"No jpg files found inside subfolder '{subfolders[0]}'.\")\n",
        "        else:\n",
        "            print(f\"No subfolders found inside folder '{matching_folder[0]}'.\")\n",
        "    else:\n",
        "        print(f\"No matching folder found for: '{input_text}'\")\n",
        "        return input_text  # Return input text if no match is found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq1M_w_5SL9g",
        "outputId": "ab2c55a3-e39b-408e-957d-167476afd436"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/dataset/ISL_CSLRT_Corpus/Frames_Sentence_Level\"\n",
        "\n",
        "def display_smooth_frames(input_text):\n",
        "    \"\"\"Search for folder, retrieve jpg frames, and display them smoothly in Colab.\"\"\"\n",
        "    input_text = input_text.lower().strip()\n",
        "\n",
        "    # Step 1: Locate the folder named after the input text\n",
        "    sentence_folders = os.listdir(dataset_path)\n",
        "    matching_folder = [f for f in sentence_folders if input_text in f.lower()]\n",
        "\n",
        "    if matching_folder:\n",
        "        main_folder_path = os.path.join(dataset_path, matching_folder[0])\n",
        "\n",
        "        # Step 2: Locate the first subfolder inside the matched folder\n",
        "        subfolders = os.listdir(main_folder_path)\n",
        "        if subfolders:\n",
        "            nested_folder_path = os.path.join(main_folder_path, subfolders[0])\n",
        "\n",
        "            # Step 3: Retrieve jpg files inside the subfolder\n",
        "            jpg_files = sorted([f for f in os.listdir(nested_folder_path) if f.endswith(\".jpg\")])\n",
        "\n",
        "            if jpg_files:\n",
        "                print(f\"Displaying {len(jpg_files)} frames smoothly...\")\n",
        "\n",
        "                # Step 4: Show jpg frames in a loop without abrupt clearing\n",
        "                for img_file in jpg_files:\n",
        "                    img_path = os.path.join(nested_folder_path, img_file)\n",
        "                    frame = cv2.imread(img_path)\n",
        "\n",
        "                    if frame is not None:\n",
        "                        frame = cv2.resize(frame, (400, 400))  # Fixed square size\n",
        "\n",
        "                        # Draw rectangle around frame for clarity\n",
        "                        cv2.rectangle(frame, (20, 20), (380, 380), (0, 255, 0), 4)\n",
        "\n",
        "                        clear_output(wait=True)  # Clears screen but allows smooth transition\n",
        "                        cv2_imshow(frame)  # Display frame in Colab\n",
        "                        time.sleep(0.2)  # Faster transition for smoother playback\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "        return input_text  # Return input text if no match is found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2OHAf0bVAlU",
        "outputId": "17a81926-627a-47e1-80cb-52182fcb7173"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt_tab') # Download the required data package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptEdcEcET5iv",
        "outputId": "ef18c852-f288-4027-956c-45edac377bfc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/ayushirajput1/indian-sign-language?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 535M/535M [00:06<00:00, 86.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/prathumarikeri/indian-sign-language-isl?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 281M/281M [00:01<00:00, 158MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import nltk\n",
        "import kagglehub\n",
        "import time\n",
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from IPython.display import display, Image, clear_output\n",
        "\n",
        "# Download NLTK requirements\n",
        "# Download NLTK requirements\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "# Download NLTK requirements\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "  # <--- Add this line\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Remove unwanted words (auxiliaries, etc.)\n",
        "remove_words = {'is', 'am', 'are', 'was', 'were', 'will', 'shall', 'have', 'has', 'had', 'been', 'to', 'the'}\n",
        "wh_words = {'what', 'who', 'where', 'when', 'why', 'how'}\n",
        "\n",
        "# Dataset paths\n",
        "ayushi_path = kagglehub.dataset_download(\"ayushirajput1/indian-sign-language\")\n",
        "prathu_path = kagglehub.dataset_download(\"prathumarikeri/indian-sign-language-isl\")\n",
        "\n",
        "# Resolve actual directories for inner folders\n",
        "ayushi_path = os.path.join(ayushi_path, \"Dataset_train\", \"Dataset_train\")\n",
        "prathu_path = os.path.join(prathu_path, \"Indian\")\n",
        "\n",
        "# Helper to get base verb form\n",
        "def lemmatize_word(word, tag):\n",
        "    if tag.startswith('V'):\n",
        "        return lemmatizer.lemmatize(word, 'v')\n",
        "    return lemmatizer.lemmatize(word)\n",
        "\n",
        "# English → ISL (SOV order)\n",
        "def translate_to_isl(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    if \"didn't\" in sentence or \"did not\" in sentence:\n",
        "        sentence = sentence.replace(\"didn't\", \"do not\").replace(\"did not\", \"do not\")\n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "    pos_tags = pos_tag(tokens)\n",
        "\n",
        "    subject, obj, verb, others = [], [], [], []\n",
        "    for word, tag in pos_tags:\n",
        "        if word in remove_words:\n",
        "            continue\n",
        "        elif word in wh_words:\n",
        "            others.append(word)\n",
        "        elif tag.startswith('PRP') or tag in ['NNP', 'NNPS']:\n",
        "            subject.append(word)\n",
        "        elif tag.startswith('NN') or tag in ['DT', 'JJ']:\n",
        "            obj.append(word)\n",
        "        elif tag.startswith('VB'):\n",
        "            verb.append(lemmatize_word(word, tag))\n",
        "        elif word == 'not':\n",
        "            verb.insert(0, 'do not')\n",
        "        elif tag == 'RB' and word != 'not':\n",
        "            obj.append(word)\n",
        "        else:\n",
        "            others.append(word)\n",
        "\n",
        "    time_words = [w for w in others if w in ['yesterday', 'today', 'tomorrow']]\n",
        "    others = [w for w in others if w not in time_words]\n",
        "\n",
        "    isl_sentence = time_words + subject + obj + verb + others\n",
        "    return isl_sentence\n",
        "\n",
        "# Display ISL images frame by frame\n",
        "def display_images(isl_words):\n",
        "    for word in isl_words:\n",
        "        clear_output(wait=True)\n",
        "        word_glob = glob.glob(os.path.join(ayushi_path, f\"{word.capitalize()}.*.jpg\"))\n",
        "        if word_glob:\n",
        "            print(f\"Showing word image: {word_glob[0]}\")\n",
        "            display(Image(filename=word_glob[0]))\n",
        "        else:\n",
        "            print(f\"No image found for word '{word}', checking letters...\")\n",
        "            for letter in word.upper():\n",
        "                letter_folder = os.path.join(prathu_path, letter)\n",
        "                letter_images = glob.glob(os.path.join(letter_folder, \"*.jpg\"))\n",
        "                if letter_images:\n",
        "                    clear_output(wait=True)\n",
        "                    print(f\"Showing letter image for '{letter}': {letter_images[0]}\")\n",
        "                    display(Image(filename=letter_images[0]))\n",
        "                    time.sleep(1)\n",
        "                else:\n",
        "                    print(f\"Image for letter '{letter}' not found.\")\n",
        "        time.sleep(1.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "s1Eiap88SQTa",
        "outputId": "ab5cbf8e-a2a4-4a98-9c30-8948794b9f93"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'display_smooth_frames' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-44cca5227d66>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"i am sad\"\u001b[0m  \u001b[0;31m# Modify based on your dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisplay_smooth_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0misl_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_to_isl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTranslated ISL (SOV):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misl_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'display_smooth_frames' is not defined"
          ]
        }
      ],
      "source": [
        "sentence = \"i am sad\"  # Modify based on your dataset\n",
        "out = display_smooth_frames(sentence)\n",
        "if out == sentence:\n",
        "  isl_output = translate_to_isl(sentence)\n",
        "  print(\"\\nTranslated ISL (SOV):\", isl_output)\n",
        "  display_images(isl_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvMElWTHTWZe"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}